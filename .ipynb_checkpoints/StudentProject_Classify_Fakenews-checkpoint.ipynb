{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting fakenews using text classification\n",
    "Student project, Kari Lehtomaa , lehtomaa.kari@gmail.com\n",
    "![Fakenews](fn.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Today, fake news are widely used in polictics elections to influence people with the wrong and false information. Socialmedia is very easy media to spread false information and sometimes it is not easy to know what is true or not. Many of us don't bother to check information from other sources.\n",
    "\n",
    "In this project we make a text classifier to detect fakenews. Same methods can be used to classifu and detect any false information.\n",
    "\n",
    "We will use Kaggledata for this and this is binary classification problem.\n",
    "Datasource used is: https://www.kaggle.com/jruvika/fake-news-detection\n",
    "\n",
    "This project is available in Github too: https://github.com/kleh/ML_Fakenews_LogisticsRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Formulation\n",
    "Our problem is classification problem. In our data features are URLs,Headline and Body. \n",
    "\n",
    "Labels are 1 for true and 0 for fake. We could use also body as a feature but that could make operations slow.\n",
    "For the ML classifier we will convert text to number vectors, called bags of words. To prevent differencies with different length of texts, we will also convert vectors to inverse term frequencies.\n",
    "\n",
    "We do classifying using two ML methods:\n",
    "- Naive Bayes Multinomial , this method is suitable for text counts and works also for tf-idf term frequencies, see: https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB\n",
    "- SGDClassifier, this method uses regularized linear models with stochastic gradient descent learning: the gradient of the loss is estimated each sample at a time and the model is updated along the way with a decreasing strength schedule. See: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html#sklearn.linear_model.SGDClassifier \n",
    "\n",
    "For the quality of our models we will use confusion matrix and report for precision, recall and f1-score. Precision tells us that how much are predicted correctly , and recall tells that how much are correctly predicted as for that label. The f1-score is a harmonic mean of the precision and recall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Start with loading some libraries, and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/jruvika/fake-news-detection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.bbc.com/news/world-us-canada-414191...</td>\n",
       "      <td>Four ways Bob Corker skewered Donald Trump</td>\n",
       "      <td>Image copyright Getty Images\\nOn Sunday mornin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.reuters.com/article/us-filmfestiva...</td>\n",
       "      <td>Linklater's war veteran comedy speaks to moder...</td>\n",
       "      <td>LONDON (Reuters) - “Last Flag Flying”, a comed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.nytimes.com/2017/10/09/us/politics...</td>\n",
       "      <td>Trump’s Fight With Corker Jeopardizes His Legi...</td>\n",
       "      <td>The feud broke into public view last week when...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.reuters.com/article/us-mexico-oil-...</td>\n",
       "      <td>Egypt's Cheiron wins tie-up with Pemex for Mex...</td>\n",
       "      <td>MEXICO CITY (Reuters) - Egypt’s Cheiron Holdin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.cnn.com/videos/cnnmoney/2017/10/08/...</td>\n",
       "      <td>Jason Aldean opens 'SNL' with Vegas tribute</td>\n",
       "      <td>Country singer Jason Aldean, who was performin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                URLs  \\\n",
       "0  http://www.bbc.com/news/world-us-canada-414191...   \n",
       "1  https://www.reuters.com/article/us-filmfestiva...   \n",
       "2  https://www.nytimes.com/2017/10/09/us/politics...   \n",
       "3  https://www.reuters.com/article/us-mexico-oil-...   \n",
       "4  http://www.cnn.com/videos/cnnmoney/2017/10/08/...   \n",
       "\n",
       "                                            Headline  \\\n",
       "0         Four ways Bob Corker skewered Donald Trump   \n",
       "1  Linklater's war veteran comedy speaks to moder...   \n",
       "2  Trump’s Fight With Corker Jeopardizes His Legi...   \n",
       "3  Egypt's Cheiron wins tie-up with Pemex for Mex...   \n",
       "4        Jason Aldean opens 'SNL' with Vegas tribute   \n",
       "\n",
       "                                                Body  Label  \n",
       "0  Image copyright Getty Images\\nOn Sunday mornin...      1  \n",
       "1  LONDON (Reuters) - “Last Flag Flying”, a comed...      1  \n",
       "2  The feud broke into public view last week when...      1  \n",
       "3  MEXICO CITY (Reuters) - Egypt’s Cheiron Holdin...      1  \n",
       "4  Country singer Jason Aldean, who was performin...      1  "
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"fakenews.csv\",sep=\",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model we need Headline and Body for the features and Label for label (y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dataset\n",
    "Combine text columns to new column and drop original columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>http://www.bbc.com/news/world-us-canada-414191...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.reuters.com/article/us-filmfestiva...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.nytimes.com/2017/10/09/us/politics...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>https://www.reuters.com/article/us-mexico-oil-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>http://www.cnn.com/videos/cnnmoney/2017/10/08/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Label                                               text\n",
       "0      1  http://www.bbc.com/news/world-us-canada-414191...\n",
       "1      1  https://www.reuters.com/article/us-filmfestiva...\n",
       "2      1  https://www.nytimes.com/2017/10/09/us/politics...\n",
       "3      1  https://www.reuters.com/article/us-mexico-oil-...\n",
       "4      1  http://www.cnn.com/videos/cnnmoney/2017/10/08/..."
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = df[['URLs','Headline','Body', 'Label']]\n",
    "dataset['text'] = dataset['URLs'] + \" \" + dataset['Headline'] + \" \" + dataset['Body']\n",
    "dataset = dataset.drop(['Headline'], axis=1)\n",
    "dataset = dataset.drop(['URLs'], axis=1)\n",
    "dataset = dataset.drop(['Body'], axis=1)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some statistics about our data, there is 2120 fakenews and 1868 true news. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2120</td>\n",
       "      <td>2120</td>\n",
       "      <td>http://dailybuzzlive.com/256-years-old-man-rev...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1868</td>\n",
       "      <td>1868</td>\n",
       "      <td>http://www.cnn.com/2017/10/09/us/las-vegas-sho...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       text                                                               \n",
       "      count unique                                                top freq\n",
       "Label                                                                     \n",
       "0      2120   2120  http://dailybuzzlive.com/256-years-old-man-rev...    1\n",
       "1      1868   1868  http://www.cnn.com/2017/10/09/us/las-vegas-sho...    1"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby('Label').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load need libraries and transform features for ML methods.\n",
    "\n",
    "Add a helper function we need to remove some unneeded characters from the text\n",
    "\n",
    "Then following operations will be done:\n",
    "\n",
    "1. Use helper function to remove some unneeded characters from the text\n",
    "2. Split data to Train and Test datasets\n",
    "3. Do CountVectorising transform for Train and Test feature-data, which will build sparse datasets containing tokenized words and their counts in the data. See: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html\n",
    "4. Do TfidfTransformer transform for Train and Test feature-data, Weigh the counts, so that frequent tokens get lower weight ,inverse document frequency.\n",
    "See: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfTransformer.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNotNeededChars(mess):\n",
    "    mess = str(mess)\n",
    "    mess = mess.replace(\"\\n\",\" \")\n",
    "    xx = [x for x in mess if x not in string.punctuation]\n",
    "    xx = ''.join(xx)\n",
    "    return xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['text'] = dataset['text'].apply(removeNotNeededChars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split to train and test/validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset['text'], dataset['Label'], test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "countsv = CountVectorizer()\n",
    "X_traincv = countsv.fit_transform(X_train)\n",
    "X_testcv = countsv.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49139\n"
     ]
    }
   ],
   "source": [
    "print(len(countsv.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "tfidf_transformer.fit(X_traincv)\n",
    "X_train_tfidf = tfidf_transformer.transform(X_traincv)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_testcv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X arrays are now sparse matrix arrays containing mostly 0. Only columns containing words in a sentence have some other value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2806, 49139)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit our models and get results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our first model Naive Bayes MultinomialNB, it can be used with sparse arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)\n",
    "bayes_predy = clf.predict(X_test_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9260182876142976"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(bayes_predy == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[579,  58],\n",
       "       [ 31, 535]])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, bayes_predy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.91      0.93       637\n",
      "           1       0.90      0.95      0.92       566\n",
      "\n",
      "    accuracy                           0.93      1203\n",
      "   macro avg       0.93      0.93      0.93      1203\n",
      "weighted avg       0.93      0.93      0.93      1203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, bayes_predy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision tells us that 95% of fake news are predicted correctly , and recall tells that 93% of news are correctly predicted as fake news. The f1-score is a harmonic mean of the precision and recall. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second model we use is SGDClassifier\n",
    "In this case we build Pipeline to make operations easier. Pipeline will run CountVectorizer, TfidfTransformer and SGDClassifier. So we input splitted data and fo transformations and classifying in one call.\n",
    "\n",
    "As a hyperparameters for SGDRegression:\n",
    "- loss is default hinge\n",
    "- alpha = 1e-03, The higher the value, the stronger the regularization\n",
    "- random_state = 42 , use similar state for multiple runs\n",
    "- max_iter = 20 , keep iterations low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "mytestpl = Pipeline([\n",
    "('cv', CountVectorizer()),\n",
    "('tfidf', TfidfTransformer()),\n",
    "('cgf', SGDClassifier(loss='hinge', alpha=1e-3, random_state=42,max_iter=20)),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the pipeline we provide data which is not CountVectorized or tf-idf:d. Those operations will be done in the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytestpl.fit(X_train, y_train)\n",
    "sgd_predy = mytestpl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[617,  20],\n",
       "       [ 15, 551]])"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, sgd_predy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       637\n",
      "           1       0.96      0.97      0.97       566\n",
      "\n",
      "    accuracy                           0.97      1203\n",
      "   macro avg       0.97      0.97      0.97      1203\n",
      "weighted avg       0.97      0.97      0.97      1203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, sgd_predy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use GridSearch to search optimal hyperparameters\n",
    "Load the library and list of hyperparameters and possible values to test. We use the previous pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    ">>> parameters = {\n",
    "'cv__ngram_range': [(1, 1), (1, 2)],\n",
    "'tfidf__use_idf': (True, False),\n",
    "'cgf__alpha': (1e-2, 1e-3),\n",
    "'cgf__max_iter': (20,40,60)    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_cgf = GridSearchCV(mytestpl, parameters, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the gridsearch to start getting the good hyperparameters. This can take some time, about few minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_cgf = gs_cgf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After run, we get best params for our pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cgf__alpha': 0.001,\n",
       " 'cgf__max_iter': 20,\n",
       " 'cv__ngram_range': (1, 2),\n",
       " 'tfidf__use_idf': True}"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cgf.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do prediction and get classification report with these params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_gs_predy = gs_cgf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.95      0.97       637\n",
      "           1       0.95      0.98      0.96       566\n",
      "\n",
      "    accuracy                           0.97      1203\n",
      "   macro avg       0.96      0.97      0.97      1203\n",
      "weighted avg       0.97      0.97      0.97      1203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, sgd_gs_predy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive Bayes gave pretty good results. With SGDRegressor we got only little bit better. \n",
    "\n",
    "\n",
    "It may be that data is too good, at least true news contains lot of \"CITY (Reuters)\" , which can make classifying easy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the quite easy code, it is possible to classify texts quite precily. Features could be prepared better using NLTK: https://www.nltk.org/ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

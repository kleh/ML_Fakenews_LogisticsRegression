{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting fakenews, text classification\n",
    "Student project, Kari Lehtomaa , lehtomaa.kari@gmail.com\n",
    "![Fakenews](fn.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Today, fake news are widely used in polictics elections to influence people with the wrong and false information. Socialmedia is very easy media to spread false information and sometimes it is not easy to know what is true or not. Many of us don't bother to check information from other sources.\n",
    "\n",
    "In this project we make a text classifier to detect fakenews. Same methods can be used to classifu and detect any false information.\n",
    "\n",
    "We will use Kaggledata for this and this is binary classification problem.\n",
    "Datasource used is: https://www.kaggle.com/jruvika/fake-news-detection\n",
    "\n",
    "This project is available in Github too: https://github.com/kleh/ML_Fakenews_LogisticsRegression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Formulation\n",
    "In our data our features are text and label is 1 for true and 0 for fake.\n",
    "For the ML classifier we will convert text to number vectors, called bags of words. To prevent differencies with different length of texts, we will also convert vectors to term frequencies.\n",
    "\n",
    "We do classifying using two ML methods:\n",
    "- Naive Bayes Multinomial , ? EXPLAIN\n",
    "- SGDClassifier, ? EXPLAIN\n",
    "\n",
    "For the quality of our models we will use confusion matrix and report for precision, recall and f1-score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Same type of task can be found from sklearn tutorial: https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html\n",
    "\n",
    "Let's start with loading some libraries, and loading data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/jruvika/fake-news-detection\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>URLs</th>\n",
       "      <th>Headline</th>\n",
       "      <th>Body</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://www.bbc.com/news/world-us-canada-414191...</td>\n",
       "      <td>Four ways Bob Corker skewered Donald Trump</td>\n",
       "      <td>Image copyright Getty Images\\nOn Sunday mornin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.reuters.com/article/us-filmfestiva...</td>\n",
       "      <td>Linklater's war veteran comedy speaks to moder...</td>\n",
       "      <td>LONDON (Reuters) - “Last Flag Flying”, a comed...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://www.nytimes.com/2017/10/09/us/politics...</td>\n",
       "      <td>Trump’s Fight With Corker Jeopardizes His Legi...</td>\n",
       "      <td>The feud broke into public view last week when...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.reuters.com/article/us-mexico-oil-...</td>\n",
       "      <td>Egypt's Cheiron wins tie-up with Pemex for Mex...</td>\n",
       "      <td>MEXICO CITY (Reuters) - Egypt’s Cheiron Holdin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.cnn.com/videos/cnnmoney/2017/10/08/...</td>\n",
       "      <td>Jason Aldean opens 'SNL' with Vegas tribute</td>\n",
       "      <td>Country singer Jason Aldean, who was performin...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                URLs  \\\n",
       "0  http://www.bbc.com/news/world-us-canada-414191...   \n",
       "1  https://www.reuters.com/article/us-filmfestiva...   \n",
       "2  https://www.nytimes.com/2017/10/09/us/politics...   \n",
       "3  https://www.reuters.com/article/us-mexico-oil-...   \n",
       "4  http://www.cnn.com/videos/cnnmoney/2017/10/08/...   \n",
       "\n",
       "                                            Headline  \\\n",
       "0         Four ways Bob Corker skewered Donald Trump   \n",
       "1  Linklater's war veteran comedy speaks to moder...   \n",
       "2  Trump’s Fight With Corker Jeopardizes His Legi...   \n",
       "3  Egypt's Cheiron wins tie-up with Pemex for Mex...   \n",
       "4        Jason Aldean opens 'SNL' with Vegas tribute   \n",
       "\n",
       "                                                Body  Label  \n",
       "0  Image copyright Getty Images\\nOn Sunday mornin...      1  \n",
       "1  LONDON (Reuters) - “Last Flag Flying”, a comed...      1  \n",
       "2  The feud broke into public view last week when...      1  \n",
       "3  MEXICO CITY (Reuters) - Egypt’s Cheiron Holdin...      1  \n",
       "4  Country singer Jason Aldean, who was performin...      1  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"fakenews.csv\",sep=\",\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the model we need Headline and Body for the features and Label for label (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = df[['Headline','Body', 'Label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">Headline</th>\n",
       "      <th colspan=\"4\" halign=\"left\">Body</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2137</td>\n",
       "      <td>1226</td>\n",
       "      <td>10/5 TRS-PNC Park: Bucs Win in '71, '79; Lose ...</td>\n",
       "      <td>6</td>\n",
       "      <td>2120</td>\n",
       "      <td>1193</td>\n",
       "      <td>A Potato Battery Can Light up a Room for Over ...</td>\n",
       "      <td>143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1872</td>\n",
       "      <td>1605</td>\n",
       "      <td>World Cup 2018: Who needs what to qualify for ...</td>\n",
       "      <td>5</td>\n",
       "      <td>1868</td>\n",
       "      <td>1670</td>\n",
       "      <td>Chat with us in Facebook Messenger. Find out w...</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Headline                                                                 \\\n",
       "         count unique                                                top freq   \n",
       "Label                                                                           \n",
       "0         2137   1226  10/5 TRS-PNC Park: Bucs Win in '71, '79; Lose ...    6   \n",
       "1         1872   1605  World Cup 2018: Who needs what to qualify for ...    5   \n",
       "\n",
       "       Body                                                                 \n",
       "      count unique                                                top freq  \n",
       "Label                                                                       \n",
       "0      2120   1193  A Potato Battery Can Light up a Room for Over ...  143  \n",
       "1      1868   1670  Chat with us in Facebook Messenger. Find out w...   61  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby('Label').describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Method\n",
    "Add some text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load need libraries and transform features for ML methods.\n",
    "\n",
    "Add a helper function we need to remove some unneeded characters from the text\n",
    "\n",
    "Then following operations will be done:\n",
    "\n",
    "1. Combine  Headline and Body\n",
    "2. Use helper function to remove some unneeded characters from the text\n",
    "3. Split data to Train and Test datasets\n",
    "4. Do CountVectorising transform for Train and Test feature-data, which will build sparse datasets containing words and their counts in the data.\n",
    "5. Do TfidfTransformer transform for Train and Test feature-data, which will turn word counts to frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for extracting features\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['text'] = dataset['Headline'] + \" \" + dataset['Body']\n",
    "dataset = dataset.drop(['Headline', 'Body'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNotNeededChars(mess):\n",
    "    mess = str(mess)\n",
    "    mess = mess.replace(\"\\n\",\" \")\n",
    "    xx = [x for x in mess if x not in string.punctuation]\n",
    "    xx = ''.join(xx)\n",
    "    return xx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['text'] = dataset['text'].apply(removeNotNeededChars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    dataset['text'], dataset['Label'], test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "countsv = CountVectorizer()\n",
    "X_traincv = countsv.fit_transform(X_train)\n",
    "X_testcv = countsv.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_traincv)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_testcv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "Add some text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our first model Naive Bayes MultinomialNB, it can be used with sparse arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9301745635910225"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(bayes_predy == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[585,  52],\n",
       "       [ 32, 534]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, bayes_predy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.92      0.93       637\n",
      "           1       0.91      0.94      0.93       566\n",
      "\n",
      "    accuracy                           0.93      1203\n",
      "   macro avg       0.93      0.93      0.93      1203\n",
      "weighted avg       0.93      0.93      0.93      1203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, bayes_predy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second model we use is SGDClassifier\n",
    "In this case we build Pipeline to make operations easier. Pipeline will run CountVectorizer, TfidfTransformer and SGDClassifier. So we input splitted data and fo transformations and classifying in one call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "mytestpl = Pipeline([\n",
    "('cv', CountVectorizer()),\n",
    "('tfidf', TfidfTransformer()),\n",
    "('cgf', SGDClassifier(loss='hinge', alpha=1e-3, random_state=42,max_iter=5, tol=None)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "mytestpl.fit(X_train, y_train)\n",
    "sgd_predy = mytestpl.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[622,  15],\n",
       "       [ 19, 547]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(y_test, sgd_predy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.98      0.97       637\n",
      "           1       0.97      0.97      0.97       566\n",
      "\n",
      "    accuracy                           0.97      1203\n",
      "   macro avg       0.97      0.97      0.97      1203\n",
      "weighted avg       0.97      0.97      0.97      1203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, sgd_predy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible GridSearch ???"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter tuning\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "parameters = {\n",
    "'cv__ngram_range': [(1, 1), (1, 2)],\n",
    "'tfidf__use_idf': (True, False),\n",
    "'cgf__alpha': (1e-2, 1e-3),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_cgf = GridSearchCV(mytestpl, parameters, cv=5, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_cgf = gs_cgf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cgf__alpha': 0.001, 'cv__ngram_range': (1, 2), 'tfidf__use_idf': True}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_cgf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sgd_gs_predy = gs_cgf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.96      0.97       637\n",
      "           1       0.96      0.98      0.97       566\n",
      "\n",
      "    accuracy                           0.97      1203\n",
      "   macro avg       0.97      0.97      0.97      1203\n",
      "weighted avg       0.97      0.97      0.97      1203\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(metrics.classification_report(y_test, sgd_gs_predy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
